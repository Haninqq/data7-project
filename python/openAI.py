from fastapi import FastAPI, Depends
from pydantic import BaseModel
from sqlalchemy import create_engine, Column, Integer, String, ForeignKey
from sqlalchemy.orm import sessionmaker, Session, relationship
from sqlalchemy.ext.declarative import declarative_base
from sentence_transformers import SentenceTransformer, util
import os
from dotenv import load_dotenv
from openai import OpenAI
import logging
import json
from fastapi.responses import JSONResponse
import pandas as pd
from contextlib import asynccontextmanager


# ------------------------------
# FastAPI ì•± & DB ì„¤ì • & SBERT ëª¨ë¸ ë¡œë”©
# ------------------------------

app = None
# ì „ì—­ë³€ìˆ˜ ì„ ì–¸ 
content_df = None
content_embeddings = None
# SBERT ëª¨ë¸ ë¡œë”©
model = None

# OpenAI API í‚¤ ë¡œë”©
load_dotenv()  
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))  

# DB ì„¤ì •
SQLALCHEMY_DATABASE_URL = "mysql+pymysql://root:1234@localhost/instdesign"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"charset": "utf8mb4"})
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()

# Lifespan ì„¤ì •
@asynccontextmanager
async def lifespan(app):
    global model, content_df, content_embeddings

    print("ğŸš€ ëª¨ë¸ ë° ì½˜í…ì¸  ë¡œë”© ì¤‘...")
    model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')

    # âœ… ì—¬ê¸°ì„œ ì§ì ‘ DB ì„¸ì…˜ ìƒì„±
    db = SessionLocal()
    try:
        rows = db.query(Content).all()
        content_df = pd.DataFrame([{
            "id": row.id,
            "subject": row.subject,
            "topic": row.topic,
            "subtitle": row.subtitle,
            "title": row.title,
            "keywords": row.keywords,
            "url": row.url
        } for row in rows])

        content_keywords = content_df["keywords"].astype(str).fillna("").tolist()
        content_embeddings = model.encode(content_keywords, convert_to_tensor=True)

        print("âœ… ì½˜í…ì¸  ë¡œë”© ë° ì„ë² ë”© ì™„ë£Œ")

        yield  # ì—¬ê¸°ê¹Œì§€ ì˜¤ë©´ ì„œë²„ ì‹œì‘ë¨

    finally:
        db.close()  # âœ… ê¼­ ì„¸ì…˜ ë‹«ì•„ì£¼ê¸°
        print("ğŸ›‘ DB ì„¸ì…˜ ì¢…ë£Œ")


# ì•± ì„ ì–¸ë¶€ì—ì„œ lifespan ë“±ë¡
app = FastAPI(lifespan=lifespan)

# ------------------------------
# DB ëª¨ë¸ ì •ì˜
# ------------------------------
class TaxonomyCategory(Base):
    __tablename__ = "taxonomy_category"

    id = Column(Integer, primary_key=True, index=True)
    category = Column(String(20), nullable=False)      # ì˜ì–´ ì´ë¦„ (ì˜ˆ: Remembering)
    category_kor = Column(String(20), nullable=False)  # í•œê¸€ ì´ë¦„ (ì˜ˆ: ê¸°ì–µí•˜ê¸°)


class TaxonomyVerbs(Base):
    __tablename__ = "taxonomy_verbs"

    id = Column(Integer, primary_key=True, index=True)
    category_id = Column(Integer, ForeignKey("taxonomy_category.id"), nullable=False)
    verb_eng = Column(String(50), nullable=False)
    verb_kor = Column(String(50), nullable=False)
    desc = Column(String(200), nullable=True)

    category = relationship("TaxonomyCategory", backref="verbs")
    tool_adt_maps = relationship("ToolAdtMap", back_populates="taxonomy_verb")

class Tools(Base):
    __tablename__ = 'tools'
    
    id = Column(Integer, primary_key=True)
    name = Column(String(100), nullable=False)
    description = Column(String(255), nullable=True)

    # tool_adt_mapì™€ ê´€ê³„ ì„¤ì • (optional)
    tool_adt_maps = relationship("ToolAdtMap", back_populates="tool")

class ToolAdtMap(Base):
    __tablename__ = 'tool_adt_map'

    tool_id = Column(Integer, ForeignKey('tools.id'), primary_key=True)
    verb_id = Column(Integer, ForeignKey('taxonomy_verbs.id'), primary_key=True)

    # ê´€ê³„ ì„¤ì •
    tool = relationship("Tools", back_populates="tool_adt_maps")
    taxonomy_verb = relationship("TaxonomyVerbs", back_populates="tool_adt_maps")

class Content(Base):
    __tablename__ = 'content'

    id = Column(Integer, primary_key=True, autoincrement=True)
    subject = Column(String(10), nullable=True)
    topic = Column(String(25), nullable=True)
    subtitle = Column(String(50), nullable=True)
    title = Column(String(100), nullable=True)
    keywords = Column(String(400), nullable=True)
    url = Column(String(100), nullable=True)

# ------------------------------
# ìš”ì²­ ë°ì´í„° ëª¨ë¸ --> Springì—ì„œ ë°›ì•„ì˜¤ëŠ” ë°ì´í„°í„°
# ------------------------------
class RequestData(BaseModel):
    grade: str
    subject: str
    goal: str

# ------------------------------
# DB ì„¸ì…˜ ì˜ì¡´ì„±
# ------------------------------
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# ------------------------------
# ADT í•­ëª© DBì—ì„œ ê°€ì ¸ì˜¤ê¸°
# ------------------------------
def get_adt_items(db: Session):
    results = (
        db.query(
            TaxonomyVerbs.category_id,
            TaxonomyCategory.category_kor.label("bloom_name"),
            TaxonomyVerbs.verb_kor,
            TaxonomyVerbs.desc
        )
        .join(TaxonomyCategory, TaxonomyVerbs.category_id == TaxonomyCategory.id)
        .all()
    )

    return [
        {
            "category_id": category_id,
            "bloom_name": bloom_name,
            "verb": verb,
            "desc": desc
        }
        for category_id, bloom_name, verb, desc in results
        if verb and desc
    ]

# ------------------------------
# ADTê¸°ì¤€ tool ê°€ì ¸ì˜¤ê¸°
# ------------------------------

def get_tools(db: Session, adt_values: list):
    results = (
        db.query(
            Tools.name.label("tool_name"),
            Tools.description.label("tool_description")
        )
        .join(ToolAdtMap, Tools.id == ToolAdtMap.tool_id) 
        .join(TaxonomyVerbs, TaxonomyVerbs.id == ToolAdtMap.verb_id)  
        .filter(TaxonomyVerbs.verb_kor.in_(adt_values))  
        .all()
    )

    # tool_name ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (ê°€ì¥ ë¨¼ì € ë‚˜ì˜¨ ê±¸ ì±„íƒ)
    tool_dict = {}
    for tool_name, tool_description in results:
        if tool_name not in tool_dict:
            tool_dict[tool_name] = tool_description

    # dictë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    return [
        {
            "tool_name": tool_name,
            "tool_description": tool_description
        }
        for tool_name, tool_description in tool_dict.items()
    ]

# ------------------------------
# ì½˜í…ì¸  ìœ ì‚¬ë„ ë¶„ì„ í•¨ìˆ˜
# ------------------------------
# ê³¼ëª© ë§¤í•‘ í…Œì´ë¸”
subject_map = {
    "êµ­ì–´": None, "ìˆ˜í•™": None, "ë°”ë¥¸ ìƒí™œ": None, "ìŠ¬ê¸°ë¡œìš´ ìƒí™œ": None, "ì¦ê±°ìš´ ìƒí™œ": None,
    "ì‚¬íšŒ": "ì‚¬íšŒ", "ë„ë•": "ì‚¬íšŒ", "ì—­ì‚¬": "ì‚¬íšŒ",
    "ê³¼í•™": "ê³¼í•™", "ê³¼í•™/ê¸°ìˆ ": "ê³¼í•™",
    "ê°€ì •/ì •ë³´": "ê¸°ìˆ Â·ê°€ì •Â·ì‹¤ê³¼", "ê¸°ê°€/ì •ë³´": "ê¸°ìˆ Â·ê°€ì •Â·ì‹¤ê³¼", "ê¸°ìˆ ê°€ì •/ì •ë³´": "ê¸°ìˆ Â·ê°€ì •Â·ì‹¤ê³¼",
    "ê¸°ìˆ Â·ê°€ì •Â·ì‹¤ê³¼": "ê¸°ìˆ Â·ê°€ì •Â·ì‹¤ê³¼", "ì²´ìœ¡": "ì²´ìœ¡",
    "ì˜ˆìˆ ": None, "ìŒì•…": "ìŒì•…", "ë¯¸ìˆ ": "ë¯¸ìˆ ", "ì˜ˆìˆ (ìŒì•…/ë¯¸ìˆ )": "ìŒì•…",
    "ì˜ì–´": None, "í•œêµ­ì‚¬": "ì‚¬íšŒ", "ì œ2ì™¸êµ­ì–´/í•œë¬¸": None
}

def recommend_learning_content(
    input_learning_objective: str,
    user_subject: str,
    model,
    content_df,
    content_embeddings,
    top_n: int = 3,
    threshold: float = 0.5
):
    # ì„¤ëª…
    """
    ì‚¬ìš©ìì˜ í•™ìŠµ ëª©í‘œ ë¬¸ì¥ê³¼ ê³¼ëª©ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ì½˜í…ì¸  ì¶”ì²œ
    - input_learning_objective: ì‚¬ìš©ì ì…ë ¥ ë¬¸ì¥
    - user_subject: 'ê°€ì •/ì •ë³´'ì™€ ê°™ì€ ì‹¤ì œ ì‚¬ìš©ì ì…ë ¥
    - model: SBERT ëª¨ë¸
    - content_df: ì „ì²´ ì½˜í…ì¸  DataFrame
    - content_embeddings: SBERT ì„ë² ë”©ëœ ë²¡í„° (Tensor)
    - top_n: ì¶”ì²œ ê°œìˆ˜
    - threshold: ìœ ì‚¬ë„ ê¸°ì¤€ (ê¸°ë³¸ 0.5 ì´ìƒë§Œ ì¶”ì²œ)

    Returns: ì¶”ì²œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ or ì—ëŸ¬ ë©”ì‹œì§€ dict
    """

    # ê³¼ëª© ë§¤í•‘
    mapped_subject = subject_map.get(user_subject)
    if not mapped_subject:
        return {"message": f"'{user_subject}' ê³¼ëª©ì€ ì½˜í…ì¸  DBì— ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ë§¤í•‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    # ê³¼ëª© í•„í„°ë§
    filtered_df = content_df[content_df["subject"] == mapped_subject].copy()
    if filtered_df.empty:
        return {"message": f"ë§¤í•‘ëœ ê³¼ëª© '{mapped_subject}'ì— í•´ë‹¹í•˜ëŠ” ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤."}

    # ì…ë ¥ ë¬¸ì¥ ë²¡í„°í™”
    input_embedding = model.encode(input_learning_objective, convert_to_tensor=True)

    # ì„ë² ë”© ìŠ¬ë¼ì´ì‹± (Tensor ê¸°ë°˜)
    filtered_embeddings = content_embeddings[filtered_df.index.tolist()]

    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = util.cos_sim(input_embedding, filtered_embeddings)[0]
    filtered_df["Similarity"] = similarities.cpu().numpy()

    # ìœ ì‚¬ë„ ê¸°ì¤€ ì´ìƒ ì½˜í…ì¸  ìƒìœ„ Nê°œ ì •ë ¬
    top_contents = filtered_df[filtered_df["Similarity"] >= threshold] \
        .sort_values(by="Similarity", ascending=False).head(top_n)

    if top_contents.empty:
        return {"message": f"ìœ ì‚¬í•œ ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤. (ìœ ì‚¬ë„ {threshold} ì´ìƒ ì—†ìŒ)"}

    # ê²°ê³¼ í¬ë§· êµ¬ì„±
    return [
        {
            "topic": row["topic"],
            "subtitle": row["subtitle"].strip(),
            "title": row["title"],
            "url": row["url"],
            "similarity": round(row["Similarity"], 4)
        }
        for _, row in top_contents.iterrows()
    ]



# ------------------------------
# ìœ ì‚¬ë„ ë¶„ì„ í•¨ìˆ˜
# ------------------------------
def find_similar_adts(user_input: str, adt_items: list, top_n: int = 3):
    adt_texts = [f"{item['verb']} - {item['desc']}" for item in adt_items]
    user_embedding = model.encode(user_input, convert_to_tensor=True)
    adt_embeddings = model.encode(adt_texts, convert_to_tensor=True)

    similarities = util.cos_sim(user_embedding, adt_embeddings)[0]
    top_results = similarities.topk(k=top_n)

    results = []
    for score, idx in zip(top_results.values, top_results.indices):
        item = adt_items[idx]
        results.append({
            "BloomTaxonomy": f"{item['bloom_name']}",
            "ADT": f"{item['verb']}",
            "ADTDesc": f"{item['desc']}",
            "Similarity": float(score)
        })

    return results

# ------------------------------
# ë¼ìš°í„° ì •ì˜
# ------------------------------
@app.post("/submit/")
def generate_similar_adts(req: RequestData, db: Session = Depends(get_db)):

    adt_items = get_adt_items(db)
    results = find_similar_adts(req.goal.strip(), adt_items)
    
    adtList = [result["ADT"] for result in results]
    tools = get_tools(db, adtList) # tool ê°€ì ¸ì˜´
    print("tools", tools)
    contentResults = recommend_learning_content(req.goal.strip(), req.subject, model, content_df, content_embeddings)


    prompt = f"""
You must always use the following instructional context when generating learning activities.

### Instructional Info:
- Subject: {req.subject}
- Grade: {req.grade}
- Learning Objective: {req.goal}

### Cognitive Elements:
- Bloom Levels: {results[0]['BloomTaxonomy']}, {results[1]['BloomTaxonomy']}, {results[2]['BloomTaxonomy']}
- ADT_kor: {results[0]['ADT']}, {results[1]['ADT']}, {results[2]['ADT']}
- ADT_desc: {results[0]['ADTDesc']}, {results[1]['ADTDesc']}, {results[2]['ADTDesc']}

### Tool List: {tools}

Always return output in the following format:

### Output Format (in Korean):
[{{
    "activity_title": "",
    "tool_name": "",
    "activity_desc": "",
    "activity_sentence": "[tool_name]ì„ í™œìš©í•˜ì—¬ [activity_title]ì„ í•´ë³¸ë‹¤."
}},
...
]


"""

    # GPT-4o-mini í˜¸ì¶œ
    response = client.responses.create(
        model="gpt-4.1",
        input=prompt,
        temperature=1,
        max_output_tokens=2048,
        top_p=1
    )

    try:
        parsed_output = json.loads(response.output_text)  # GPT ì‘ë‹µ íŒŒì‹±

        # âœ… SBERT ì¶”ì²œ ê²°ê³¼ í˜¸ì¶œ
        contentResults = recommend_learning_content(
            input_learning_objective=req.goal.strip(),
            user_subject=req.subject,
            model=model,
            content_df=content_df,
            content_embeddings=content_embeddings
        )

        if isinstance(contentResults, dict) and "message" in contentResults:
            return JSONResponse(content={
                "gptResults": parsed_output,
                "contentError": contentResults["message"]
            })

        # âœ… ë‘ ê²°ê³¼ë¥¼ í•©ì³ì„œ ì‘ë‹µ
        return JSONResponse(content={
            "gptResults": parsed_output,
            "contentResults": contentResults
        })

    except json.JSONDecodeError as e:
        logging.error("JSON íŒŒì‹± ì‹¤íŒ¨", exc_info=True)
        return JSONResponse(status_code=500, content={"error": "OpenAI ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜"})

    
    

@app.get("/")
def root():
    return {"message": "Bloom ìœ ì‚¬ë„ ë¶„ì„ APIì…ë‹ˆë‹¤."}